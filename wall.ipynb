{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOQ1BxroT6-s",
        "outputId": "855604e1-3856-4793-9092-0f5c332470bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bE1RDE13yXsw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3321e76c-ec0a-43d6-a464-7891aabe0865"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting python-dotenv==0.19.0\n",
            "  Downloading python_dotenv-0.19.0-py2.py3-none-any.whl (17 kB)\n",
            "Collecting tqdm==4.62.2\n",
            "  Downloading tqdm-4.62.2-py2.py3-none-any.whl (76 kB)\n",
            "\u001b[K     |████████████████████████████████| 76 kB 3.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.6)\n",
            "Collecting Pillow==7.0.0\n",
            "  Downloading Pillow-7.0.0-cp37-cp37m-manylinux1_x86_64.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 31.3 MB/s \n",
            "\u001b[?25hCollecting matplotlib==3.4.3\n",
            "  Downloading matplotlib-3.4.3-cp37-cp37m-manylinux1_x86_64.whl (10.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.3 MB 55.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opencv-python==4.6.0.66 in /usr/local/lib/python3.7/dist-packages (4.6.0.66)\n",
            "Requirement already satisfied: opencv-python-headless==4.6.0.66 in /usr/local/lib/python3.7/dist-packages (4.6.0.66)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.4.3) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.4.3) (2.8.2)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.4.3) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.4.3) (1.4.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib==3.4.3) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7->matplotlib==3.4.3) (1.15.0)\n",
            "Installing collected packages: Pillow, tqdm, python-dotenv, matplotlib\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.64.1\n",
            "    Uninstalling tqdm-4.64.1:\n",
            "      Successfully uninstalled tqdm-4.64.1\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bokeh 2.3.3 requires pillow>=7.1.0, but you have pillow 7.0.0 which is incompatible.\u001b[0m\n",
            "Successfully installed Pillow-7.0.0 matplotlib-3.4.3 python-dotenv-0.19.0 tqdm-4.62.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-learn==0.24.2\n",
            "  Downloading scikit_learn-0.24.2-cp37-cp37m-manylinux2010_x86_64.whl (22.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 22.3 MB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch==1.12.1 in /usr/local/lib/python3.7/dist-packages (1.12.1+cu113)\n",
            "Requirement already satisfied: torchvision==0.13.1 in /usr/local/lib/python3.7/dist-packages (0.13.1+cu113)\n",
            "Collecting pytorch-ignite\n",
            "  Downloading pytorch_ignite-0.4.10-py3-none-any.whl (264 kB)\n",
            "\u001b[K     |████████████████████████████████| 264 kB 67.8 MB/s \n",
            "\u001b[?25hCollecting segmentation-models-pytorch==0.2.0\n",
            "  Downloading segmentation_models_pytorch-0.2.0-py3-none-any.whl (87 kB)\n",
            "\u001b[K     |████████████████████████████████| 87 kB 7.7 MB/s \n",
            "\u001b[?25hCollecting albumentations==1.0.3\n",
            "  Downloading albumentations-1.0.3-py3-none-any.whl (98 kB)\n",
            "\u001b[K     |████████████████████████████████| 98 kB 10.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.2) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.2) (1.7.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.2) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.2) (1.2.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.12.1) (4.1.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.13.1) (7.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision==0.13.1) (2.23.0)\n",
            "Collecting pretrainedmodels==0.7.4\n",
            "  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 7.2 MB/s \n",
            "\u001b[?25hCollecting efficientnet-pytorch==0.6.3\n",
            "  Downloading efficientnet_pytorch-0.6.3.tar.gz (16 kB)\n",
            "Collecting timm==0.4.12\n",
            "  Downloading timm-0.4.12-py3-none-any.whl (376 kB)\n",
            "\u001b[K     |████████████████████████████████| 376 kB 47.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==1.0.3) (0.18.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations==1.0.3) (6.0)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==1.0.3) (4.6.0.66)\n",
            "Collecting munch\n",
            "  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch==0.2.0) (4.62.2)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations==1.0.3) (3.4.3)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations==1.0.3) (2.9.0)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations==1.0.3) (1.3.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations==1.0.3) (2021.11.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations==1.0.3) (2.6.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations==1.0.3) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations==1.0.3) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations==1.0.3) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations==1.0.3) (3.0.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations==1.0.3) (1.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (21.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision==0.13.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision==0.13.1) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision==0.13.1) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision==0.13.1) (2.10)\n",
            "Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.6.3-py3-none-any.whl size=12422 sha256=3c314ccd2e3807dddb51fb71185c28508e704d39ca0bf1533bf3aca2cdb1a31b\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/6b/0c/f0ad36d00310e65390b0d4c9218ae6250ac579c92540c9097a\n",
            "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60966 sha256=7f39cf9dac7e7e762d00d8be3f8ce7de26a9f0e9b9c0efb3872a39ef7ca41981\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/27/e8/9543d42de2740d3544db96aefef63bda3f2c1761b3334f4873\n",
            "Successfully built efficientnet-pytorch pretrainedmodels\n",
            "Installing collected packages: munch, timm, pretrainedmodels, efficientnet-pytorch, segmentation-models-pytorch, scikit-learn, pytorch-ignite, albumentations\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "  Attempting uninstall: albumentations\n",
            "    Found existing installation: albumentations 1.2.1\n",
            "    Uninstalling albumentations-1.2.1:\n",
            "      Successfully uninstalled albumentations-1.2.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.5 requires scikit-learn>=1.0.0, but you have scikit-learn 0.24.2 which is incompatible.\u001b[0m\n",
            "Successfully installed albumentations-1.0.3 efficientnet-pytorch-0.6.3 munch-2.5.0 pretrainedmodels-0.7.4 pytorch-ignite-0.4.10 scikit-learn-0.24.2 segmentation-models-pytorch-0.2.0 timm-0.4.12\n"
          ]
        }
      ],
      "source": [
        "!pip install python-dotenv==0.19.0 tqdm==4.62.2 numpy Pillow==7.0.0 matplotlib==3.4.3 opencv-python==4.6.0.66 opencv-python-headless==4.6.0.66 matplotlib\n",
        "!pip install scikit-learn==0.24.2 torch==1.12.1 torchvision==0.13.1 pytorch-ignite segmentation-models-pytorch==0.2.0 albumentations==1.0.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8hpHLWYv9Ak"
      },
      "outputs": [],
      "source": [
        "## Импорт необходимых библиотек\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
        "from ignite.metrics import Loss, Metric\n",
        "from ignite.engine import _prepare_batch\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import json\n",
        "import base64\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "from PIL import Image\n",
        "import segmentation_models_pytorch as smp\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from typing import Callable, Tuple, Dict, Any, List, Sequence, Iterator, Optional\n",
        "from collections import defaultdict\n",
        "from torchvision.models.detection.faster_rcnn import fasterrcnn_resnet50_fpn, FastRCNNPredictor\n",
        "\n",
        "from ipywidgets import IntProgress\n",
        "from IPython.display import display\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Сегментация стен + окна"
      ],
      "metadata": {
        "id": "JpuBZnpskZ9r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Вспомогательные функции"
      ],
      "metadata": {
        "id": "gtIDdncUkiyS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ja9_yj7rAHmn"
      },
      "outputs": [],
      "source": [
        "## PLRC DATASET - класс и необходимые функции для датасета\n",
        "\n",
        "def get_color_map():\n",
        "    return {\n",
        "        \"wall\": 255,\n",
        "        \"window\": 255\n",
        "    }\n",
        "\n",
        "def tensor_from_rgb_image(image: np.ndarray) -> torch.Tensor:\n",
        "    image = np.moveaxis(image, -1, 0)\n",
        "    image = np.ascontiguousarray(image)\n",
        "    image = torch.from_numpy(image)\n",
        "    return image\n",
        "\n",
        "\n",
        "def tensor_from_mask_image(mask: np.ndarray) -> torch.Tensor:\n",
        "    if len(mask.shape) == 2:\n",
        "        mask = np.expand_dims(mask, -1)\n",
        "    return tensor_from_rgb_image(mask)\n",
        "\n",
        "\n",
        "class PLRCDataset(Dataset):\n",
        "    def __init__(self, image_folder, transform, start_index, end_index, mask_folder=None):\n",
        "        self.image_folder = image_folder\n",
        "        self.mask_folder = mask_folder\n",
        "        self.transform = transform\n",
        "\n",
        "        self.images = PLRCDataset.parse_folder(self.image_folder, start_index, end_index)\n",
        "        self.color_map = get_color_map()\n",
        "\n",
        "    @staticmethod\n",
        "    def parse_folder(path, start, end):\n",
        "        if path is None:\n",
        "            return []\n",
        "        images = glob.glob1(path,  '*.png')\n",
        "        images.sort()\n",
        "\n",
        "        return images[start:end]\n",
        "\n",
        "    @staticmethod\n",
        "    def load_image(path) -> np.array:\n",
        "        return cv2.imread(path, 0)\n",
        "\n",
        "    @staticmethod\n",
        "    def load_mask(path) -> np.array:\n",
        "        return cv2.imread(path, 0)\n",
        "\n",
        "    @staticmethod\n",
        "    def split_grayscale_mask_into_channels_by_color_map(mask, color_map) -> torch.Tensor:\n",
        "        masks = []\n",
        "\n",
        "        for i in color_map.values():\n",
        "            masks.append(mask == i)\n",
        "\n",
        "        return torch.cat(masks).float()\n",
        "\n",
        "    def mask_to_grayscale(self, masks) -> np.ndarray:\n",
        "        masks = masks.cpu().numpy()\n",
        "\n",
        "        colors_by_index = list(self.color_map.values())\n",
        "        img = np.zeros(masks.shape[1:], dtype=np.uint8)\n",
        "\n",
        "        for i in range(len(masks)):\n",
        "            img[masks[i] == 1] = colors_by_index[i]\n",
        "\n",
        "        return img\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_name = self.images[index]\n",
        "        image_path = os.path.join(self.image_folder, image_name)\n",
        "\n",
        "        image = PLRCDataset.load_image(image_path)\n",
        "\n",
        "        if self.mask_folder is None:\n",
        "            # sample = self.transform(image=image)\n",
        "            # image = sample['image']\n",
        "            return image_name, tensor_from_mask_image(image).float() / 255.0\n",
        "\n",
        "        mask_path = os.path.join(self.mask_folder, image_name)\n",
        "        mask = PLRCDataset.load_mask(mask_path)\n",
        "\n",
        "        sample = self.transform(image=image, mask=mask)\n",
        "        image, mask = sample['image'], sample['mask']\n",
        "\n",
        "        image = tensor_from_mask_image(image)\n",
        "        image = torch.cat([image, image, image])\n",
        "        mask = tensor_from_mask_image(mask)\n",
        "\n",
        "        mask = PLRCDataset.split_grayscale_mask_into_channels_by_color_map(mask, self.color_map)\n",
        "\n",
        "        return image.float() / 255.0, mask\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "## PLRC UTILS = утилиты для подсчета\n",
        "\n",
        "def get_training_augmentation():\n",
        "    return A.Compose([\n",
        "        # A.RandomCrop(height=256, width=256, p=1),\n",
        "        A.Normalize(mean=(0.5,), std=(0.5,)),\n",
        "        A.VerticalFlip(p=0.5),              \n",
        "        A.RandomRotate90(p=0.5),\n",
        "        #A.CLAHE(),\n",
        "        A.RandomBrightnessContrast(p=0.5)    \n",
        "        #A.RandomGamma(p=0.5)\n",
        "    ], p=1)\n",
        "\n",
        "def get_test_augmentation():\n",
        "    return A.Compose([\n",
        "        A.Normalize(mean=(0.5,), std=(0.5,)),\n",
        "    ], p=1)\n",
        "\n",
        "\n",
        "def get_data_loader(path, batch_size, n_processes, start_index, end_index, shuffle=True):\n",
        "    image_path = os.path.join(path, 'image')\n",
        "    mask_path = os.path.join(path, 'mask')\n",
        "\n",
        "    dataset = PLRCDataset(image_folder=image_path, mask_folder=mask_path, transform=get_training_augmentation(), \n",
        "                          start_index=start_index, end_index=end_index)\n",
        "\n",
        "    return DataLoader(dataset=dataset, batch_size=batch_size, drop_last=True, num_workers=n_processes, shuffle=shuffle)\n",
        "\n",
        "\n",
        "def get_train_validation_data_loaders(path, batch_size, n_processes, train_split):\n",
        "    files_count = len(os.listdir(os.path.join(path, 'image')))\n",
        "\n",
        "    train_dl = get_data_loader(path, batch_size, n_processes, shuffle=True, start_index=0, end_index=int(files_count*train_split))\n",
        "    test_dl = get_data_loader(path, batch_size, n_processes, shuffle=False, start_index=int(files_count*train_split), end_index=(files_count-1))\n",
        "    \n",
        "    return train_dl, test_dl\n",
        "\n",
        "\n",
        "## DATA LOSS - функции для подсчета метрик качества обучения нейросетей\n",
        "\n",
        "class BCESoftDiceLoss:\n",
        "    def __init__(self, dice_weight=0):\n",
        "        self.nll_loss = nn.BCEWithLogitsLoss()\n",
        "        self.dice_weight = dice_weight\n",
        "\n",
        "    @staticmethod\n",
        "    def soft_dice(predict, target):\n",
        "        eps = 1e-15\n",
        "        batch_size = target.size()[0]\n",
        "\n",
        "        dice_target = (target == 1).float().view(batch_size, -1)\n",
        "        dice_predict = torch.sigmoid(predict).view(batch_size, -1)\n",
        "\n",
        "        inter = torch.sum(dice_predict * dice_target) / batch_size\n",
        "        union = (torch.sum(dice_predict) + torch.sum(dice_target)) / batch_size + eps\n",
        "\n",
        "        return (2 * inter.float() + eps) / union.float()\n",
        "\n",
        "    def __call__(self, predict, target):\n",
        "        loss = (1.0 - self.dice_weight) * self.nll_loss(predict, target)\n",
        "\n",
        "        if self.dice_weight:\n",
        "            loss -= self.dice_weight * torch.log(BCESoftDiceLoss.soft_dice(predict, target))\n",
        "\n",
        "        return loss\n",
        "\n",
        "\n",
        "class MultiClassBCESoftDiceLoss:\n",
        "    def __init__(self, dice_weight=0):\n",
        "        self.bce_soft_dice = BCESoftDiceLoss(dice_weight)\n",
        "\n",
        "    def __call__(self, predict, target):\n",
        "        classes = target.shape[1]\n",
        "        loss = predict.new_zeros(1)\n",
        "\n",
        "        for i in range(classes):\n",
        "            loss += self.bce_soft_dice(predict[:, i].unsqueeze(1), target[:, i].unsqueeze(1))\n",
        "\n",
        "        return loss[0] / float(classes)\n",
        "\n",
        "\n",
        "class MultiClassSoftDiceMetric(Metric):\n",
        "    def __init__(self):\n",
        "        super(MultiClassSoftDiceMetric, self).__init__()\n",
        "        self.general_loss = 0\n",
        "\n",
        "    def reset(self):\n",
        "        self.general_loss = 0\n",
        "\n",
        "    def update(self, output):\n",
        "        predict, target = output\n",
        "\n",
        "        classes = target.shape[1]\n",
        "        loss = predict.new_zeros(1)\n",
        "\n",
        "        for i in range(classes):\n",
        "            loss += BCESoftDiceLoss.soft_dice(predict[:, i].unsqueeze(1), target[:, i].unsqueeze(1))\n",
        "\n",
        "        self.general_loss = loss[0] / float(classes)\n",
        "\n",
        "    def compute(self):\n",
        "        return self.general_loss\n",
        "\n",
        "## Функции для обучения\n",
        "\n",
        "def load_trained_model(model, optimizer, model_path, optimizer_path):\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    optimizer.load_state_dict(torch.load(optimizer_path))\n",
        "    print('Load model from: ', model_path)\n",
        "    print('Load optimizer from: ', optimizer_path)\n",
        "\n",
        "\n",
        "def save_model(model, optimizer, model_path, optimizer_path, postfix='_'):\n",
        "    torch.save(model.state_dict(), model_path + postfix)\n",
        "    torch.save(optimizer.state_dict(), optimizer_path + postfix)\n",
        "\n",
        "\n",
        "def log_image(image, prefix, epoch, step):\n",
        "    img = Image.fromarray(image)\n",
        "    image_name = \"%s_%s_%s.png\" % (epoch, step, prefix)\n",
        "    img.save(image_name)\n",
        "\n",
        "    os.remove(image_name)\n",
        "\n",
        "\n",
        "def run_test_model(model, evaluate_loader, epoch, device, step=10):\n",
        "    model.eval()\n",
        "    count_step = 0\n",
        "\n",
        "    for idx, batch in enumerate(evaluate_loader):\n",
        "        if count_step > step:\n",
        "            break\n",
        "\n",
        "        x, y = _prepare_batch(batch, device)\n",
        "\n",
        "        predict = model(x)\n",
        "        predict = torch.sigmoid(predict) > 0.2\n",
        "\n",
        "        count_step += len(x)\n",
        "\n",
        "    model.train()\n",
        "\n",
        "\n",
        "def run_train(dataset_path, batch_size, n_processes, model_path, optimizer_path, load_pre_model=False,\n",
        "              device='cpu', lr=0.0001, betas=(0.9, 0.99), weight_decay=0.0004, epochs=10,\n",
        "              log_interval=20, save_interval=2, train_split=1):\n",
        "\n",
        "    train_loader, evaluate_loader = get_train_validation_data_loaders(path=dataset_path, batch_size=batch_size,\n",
        "                                                                      n_processes=n_processes, train_split=train_split)\n",
        "    model = smp.FPN('resnet50', classes=24)\n",
        "\n",
        "    if device.startswith('cuda'):\n",
        "        if not torch.cuda.is_available():\n",
        "            raise ValueError('CUDA is not available')\n",
        "\n",
        "        model = model.to(device)\n",
        "        print('CUDA is used')\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=betas, weight_decay=weight_decay)\n",
        "\n",
        "    if load_pre_model:\n",
        "        load_trained_model(model, optimizer, model_path, optimizer_path)\n",
        "\n",
        "    trainer = create_supervised_trainer(model, optimizer, MultiClassBCESoftDiceLoss(0.7), device=device)\n",
        "    evaluator = create_supervised_evaluator(model,\n",
        "                                            metrics={'dice': MultiClassSoftDiceMetric(),\n",
        "                                                     'nll': Loss(MultiClassBCESoftDiceLoss(0.7))},\n",
        "                                            device=device)\n",
        "\n",
        "    desc = \"ITERATION - loss: {:.2f}\"\n",
        "    pbar = None\n",
        "\n",
        "    @trainer.on(Events.EPOCH_STARTED)\n",
        "    def create_pbar(engine):\n",
        "        model.train()\n",
        "        nonlocal pbar\n",
        "        pbar = tqdm(\n",
        "            initial=0, leave=False, total=len(train_loader),\n",
        "            desc=desc.format(0)\n",
        "        )\n",
        "\n",
        "    @trainer.on(Events.EPOCH_COMPLETED)\n",
        "    def log_training_results(engine):\n",
        "        pbar.close()\n",
        "        evaluator.run(evaluate_loader)\n",
        "        metrics = evaluator.state.metrics\n",
        "        avg_dice = metrics['dice']\n",
        "        avg_nll = metrics['nll']\n",
        "\n",
        "\n",
        "        print(\"Training Results - Epoch: {}  Dice: {:.2f} Avg loss: {:.2f}\"\n",
        "              .format(engine.state.epoch, avg_dice, avg_nll))\n",
        "\n",
        "\n",
        "        if engine.state.epoch % save_interval == 0:\n",
        "            save_model(model, optimizer, model_path, optimizer_path, '_' + list(get_color_map().keys())[0]) #str(engine.state.epoch))\n",
        "            run_test_model(model, evaluate_loader, engine.state.epoch, device)\n",
        "\n",
        "    @trainer.on(Events.ITERATION_COMPLETED)\n",
        "    def log_training_loss(engine):\n",
        "\n",
        "        pbar.desc = desc.format(engine.state.output)\n",
        "        pbar.update()\n",
        "\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    trainer.run(train_loader, max_epochs=epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Обучение"
      ],
      "metadata": {
        "id": "MVVhAvETko0H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_train(dataset_path=\"/content/drive/MyDrive/train_dataset_train/train_wall\", batch_size=16, n_processes=0,\n",
        "          model_path='/content/drive/MyDrive/model/model',\n",
        "          optimizer_path='/content/drive/MyDrive/opt/opt', device='cuda', epochs=30,\n",
        "          load_pre_model=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3f3083d-a36d-4c6a-fed1-c352ade078e8",
        "id": "a-UhPuE3mVlj"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is used\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Results - Epoch: 1  Dice: 0.84 Avg loss: 0.15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Results - Epoch: 2  Dice: 0.87 Avg loss: 0.12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Results - Epoch: 3  Dice: 0.89 Avg loss: 0.11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Results - Epoch: 4  Dice: 0.88 Avg loss: 0.11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Results - Epoch: 5  Dice: 0.89 Avg loss: 0.10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Results - Epoch: 6  Dice: 0.91 Avg loss: 0.09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Results - Epoch: 7  Dice: 0.91 Avg loss: 0.09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Results - Epoch: 8  Dice: 0.91 Avg loss: 0.10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Results - Epoch: 9  Dice: 0.90 Avg loss: 0.10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Results - Epoch: 10  Dice: 0.88 Avg loss: 0.14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Results - Epoch: 11  Dice: 0.91 Avg loss: 0.09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Results - Epoch: 12  Dice: 0.89 Avg loss: 0.10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Results - Epoch: 13  Dice: 0.89 Avg loss: 0.09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Results - Epoch: 14  Dice: 0.91 Avg loss: 0.10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Results - Epoch: 15  Dice: 0.92 Avg loss: 0.09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Results - Epoch: 16  Dice: 0.92 Avg loss: 0.08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Results - Epoch: 17  Dice: 0.91 Avg loss: 0.09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Results - Epoch: 18  Dice: 0.92 Avg loss: 0.08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Results - Epoch: 19  Dice: 0.93 Avg loss: 0.08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Results - Epoch: 20  Dice: 0.91 Avg loss: 0.12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Results - Epoch: 21  Dice: 0.93 Avg loss: 0.08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Results - Epoch: 22  Dice: 0.92 Avg loss: 0.09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Results - Epoch: 23  Dice: 0.93 Avg loss: 0.08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Results - Epoch: 24  Dice: 0.93 Avg loss: 0.08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Results - Epoch: 25  Dice: 0.92 Avg loss: 0.08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Results - Epoch: 26  Dice: 0.92 Avg loss: 0.09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ITERATION - loss: 0.06:  93%|█████████▎| 143/153 [02:45<00:11,  1.16s/it]"
          ]
        }
      ]
    }
  ]
}